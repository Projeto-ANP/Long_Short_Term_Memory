{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 11:01:45.338353: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import Objective, BayesianOptimization\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import gc\n",
    "import multiprocessing\n",
    "import threading\n",
    "\n",
    "from model_builder import ModelBuilder\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "from warnings import simplefilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 11:01:46.948245: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 11:01:46.970426: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 11:01:46.970567: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#Reproducibilty\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = 'true'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics\n",
    "\n",
    "The models will be evaluated according to the following metrics:\n",
    "\n",
    "* Root Mean Squared Error (RMSE)\n",
    "* Mean absolute percentage error (MAPE)\n",
    "* Percentage Bias Error (PBE)\n",
    "* Prediction of change in direction (POCID)\n",
    "* Mean absolute scaled error (MASE)\n",
    "* Mean absolute error (MAE)\n",
    "\n",
    "\n",
    "Considering $y_i$ as the actual value of observation $i$, $\\hat{y_i}$ as the predicted value, and $n$ as the number of observations (i.e., forecast horizon), the metrics are defined according to the equations:\n",
    "\n",
    "$RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2}$\n",
    "\n",
    "$MAPE = \\frac{1}{n}\\sum_{i=1}^{n}\\frac{|y_i - \\hat{y_i}|}{max(Ïµ,|y_i|)} \\times 100$\n",
    "\n",
    "$PBE = 100\\times\\frac{\\sum_{i=1}^{n}(y_i-\\hat{y}_i)} {\\sum_{i=1}^{n}y_i}$\n",
    "\n",
    "\\begin{equation}\n",
    "POCID = 100 \\times \\frac{\\sum_{i=2}^n}{n}D_i \\quad \\text{where:} \\quad D_i =\n",
    "\\left\\{\n",
    "\\begin{aligned}\n",
    "1 & :  (\\hat{y_i} - \\hat{y}_{i-1})(y_i - y_{i-1}) > 0\\\\\n",
    "0 & : \\text{otherwise} \\\\\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "\n",
    "$MASE = \\frac{MAE}{MAE_{naive}}$\n",
    "\n",
    "**Interpretation:** A POCID of 100 would indicate that the model always correctly predicted the change in direction of the target variable, while a POCID of 0 would indicate that the model never correctly predicted. A POCID value between 0 and 100 indicates the proportion of cases where the model correctly predicted the change in direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "  return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "def pbe(y_true, y_pred):\n",
    "  return 100*(np.sum(y_true - y_pred)/np.sum(y_true))\n",
    "\n",
    "def pocid(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    D = [1 if (y_pred[i] - y_pred[i-1]) * (y_true[i] - y_true[i-1]) > 0 else 0 for i in range(1, n)]\n",
    "    POCID = 100 * np.sum(D) / n\n",
    "    return POCID\n",
    "\n",
    "def mase(y_true, y_pred, y_baseline):\n",
    "    mae_pred = np.mean(np.abs(y_true - y_pred))\n",
    "    mae_naive = np.mean(np.abs(y_true - y_baseline))\n",
    "    result = mae_pred/mae_naive\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of the attribute-value table\n",
    "\n",
    "Machine learning algorithms receive data in attribute-value format as input, which is a set of features (x) where the last column (y) is the target. In our case, the target will be the future value of the series.\n",
    "\n",
    "The construction of this table involves the process of a rolling window, where a data window of length *l* traverses the entire series extracting the observations that will be the features and the future value that will be the target, as illustrated. At each step, the window is shifted by 1 observation. In the image, *h* represents the forecasting horizon. In the example, the model will predict the next 4 observations of the series.\n",
    "\n",
    "**Attention:** Note that in the code below, each subsequence is normalized, including the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In general, a window size capable of capturing a cycle of the data is considered\n",
    "# For example, 12 observations in the case of data with monthly frequency\n",
    "def rolling_window(series, window):\n",
    "  data = []\n",
    "  \n",
    "  # Normalizing data to the range [-1, 1] using MinMaxScaler\n",
    "  scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "  for i in range(len(series)-window):\n",
    "    example = np.array(series[i:i + window + 1])\n",
    "    example = scaler.fit_transform(example.reshape(-1, 1)).flatten()\n",
    "    data.append(example)\n",
    "    \n",
    "  df = pd.DataFrame(data)\n",
    "  return df, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division of data into training and testing subsets (holdout validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sales prediction by state (monthly), horizon = 12 will be considered\n",
    "# For sales prediction by municipality (annual), horizon = 1 will be considered\n",
    "def train_test_split_window(data, horizon):\n",
    "  X = data.iloc[:, :-1] # features\n",
    "  y = data.iloc[:, -1] # target\n",
    "\n",
    "  X_train = X[:-horizon] # features train\n",
    "  X_test =  X[-horizon:] # features test\n",
    "\n",
    "  y_train = y[:-horizon] # target train\n",
    "  y_test = y[-horizon:] # target test\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive multi-step forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_multistep_forecasting(X_test, model, horizon):\n",
    "  # The example consists of the last observed values seen\n",
    "  # In practice, it is the first example from the test set\n",
    "  example = X_test.iloc[0].values.reshape(1,-1)\n",
    "\n",
    "  preds = []\n",
    "  for i in range(horizon):\n",
    "    pred = model.predict(example)[0]\n",
    "    preds.append(pred)\n",
    "\n",
    "    # Discard the value from the first position of the feature vector\n",
    "    example = example[:,1:]\n",
    "\n",
    "    # Add the predicted value to the last position of the feature vector\n",
    "    example = np.append(example, pred)\n",
    "    example = example.reshape(1,-1)\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to convert the date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date_string):\n",
    "    year_month = date_string.strip()\n",
    "    year = int(year_month[:4])\n",
    "    month = int(year_month[4:])\n",
    "    return pd.Timestamp(year=year, month=month, day=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescaled_predicted_values(horizon, data, predictions, scaler, show_plot=None):\n",
    "    \"\"\"\n",
    "    Rescaling the predicted values to the original scale.\n",
    "\n",
    "    Parameters:\n",
    "        - horizon: int, prediction horizon.\n",
    "        - data: DataFrame, containing the time series data used for normalization.\n",
    "        - scaler: Scaler object, scaler used for normalization.\n",
    "        - predictions: array-like, containing the normalized predicted values.\n",
    "        - show_plot: bool or None, whether to display a plot of the forecasted values.\n",
    "\n",
    "    Returns:\n",
    "        - rmse_rescaled (float): Rescaled Root Mean Squared Error.\n",
    "        - mape_rescaled (float): Rescaled Mean Absolute Percentage Error.\n",
    "        - pbe_rescaled (float): Rescaled Prediction Bias Error.\n",
    "        - pocid_rescaled (float): Rescaled Percentage of Correct Indication Direction.\n",
    "        - mase_rescaled (float): Rescaled Mean Absolute Scaled Error.\n",
    "        - mae_rescaled (float): Rescaled Mean Absolute Error.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inverse MinMax\n",
    "    mat_predictions = np.zeros((len(predictions), 13)) \n",
    "    \n",
    "    for i, pred in enumerate(predictions):\n",
    "        mat_predictions[i, -1] = pred\n",
    "        \n",
    "    predictions_rescaled = scaler.inverse_transform(mat_predictions)[:, 12]\n",
    "\n",
    "    # Retrieves the actual values in the original scale\n",
    "    y_test_rescaled = data[\"m3\"][-horizon:].values\n",
    "    \n",
    "    # Calculation of evaluation metrics\n",
    "    rmse_result_rescaled = rmse(y_test_rescaled, predictions_rescaled)\n",
    "    mape_result_rescaled = mape(y_test_rescaled, predictions_rescaled)\n",
    "    pbe_result_rescaled = pbe(y_test_rescaled, predictions_rescaled)\n",
    "    pocid_result_rescaled  = pocid(y_test_rescaled, predictions_rescaled)\n",
    "    mae_result_rescaled = mean_absolute_error(y_test_rescaled, predictions_rescaled)\n",
    "    y_baseline = data[\"m3\"][-horizon*2:-horizon].values\n",
    "    mase_result_rescaled = mase(y_test_rescaled, predictions_rescaled, y_baseline)\n",
    "\n",
    "    if show_plot:\n",
    "        # Plot of the rescaled predictions\n",
    "        plt.figure(figsize=(8, 2))\n",
    "        plt.title('Predictions in original scale')\n",
    "        plt.plot(y_test_rescaled, label='Actual')\n",
    "        plt.plot(predictions_rescaled, linewidth=5, alpha=0.4, label='Predicted')\n",
    "        plt.plot(y_baseline, label='Baseline')\n",
    "        plt.scatter(range(len(y_test_rescaled)), y_test_rescaled, color='blue')\n",
    "        plt.scatter(range(len(predictions_rescaled)), predictions_rescaled, color='red')\n",
    "        plt.scatter(range(len(y_baseline)), y_baseline, color='green')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return rmse_result_rescaled, mape_result_rescaled, pbe_result_rescaled, pocid_result_rescaled, mase_result_rescaled, mae_result_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lstm_model(horizon, window, data, epochs, state, product, rescaling=None, show_plot=None, verbose=2, return_model=None):\n",
    "    \"\"\"\n",
    "    Run LSTM model for time series forecasting.\n",
    "\n",
    "    Parameters:\n",
    "        - horizon (int): Prediction horizon.\n",
    "        - window (int): Length of the window for attribute-value table generation.\n",
    "        - data (pd.DataFrame): DataFrame containing the time series data.\n",
    "        - epochs (int): Number of epochs for training the LSTM model.\n",
    "        - state: The specific state for the model (description needed based on context).\n",
    "        - product: The specific product for the model (description needed based on context).\n",
    "        - rescaling (bool or None, optional): Whether to rescale the predicted values to the original scale. Default is None.\n",
    "        - show_plot (bool or None, optional): Whether to display a plot of the forecasted values. Default is None.\n",
    "        - verbose (int, optional): Controls the verbosity of the training process. 0 = silent, 1 = progress bar, 2 = one line per epoch. Default is 2.\n",
    "        - return_model (bool or None, optional): Whether to return the trained model. Default is None.\n",
    "        \n",
    "    Returns:\n",
    "        - rmse (float): Root Mean Squared Error.\n",
    "        - mape (float): Mean Absolute Percentage Error.\n",
    "        - pbe (float): Prediction Bias Error.\n",
    "        - pocid (float): Percentage of Correct Indication Direction.\n",
    "        \n",
    "        If rescaling is True, also returns rescaled metrics:\n",
    "          - rmse_rescaled (float): Rescaled Root Mean Squared Error.\n",
    "          - mape_rescaled (float): Rescaled Mean Absolute Percentage Error.\n",
    "          - pbe_rescaled (float): Rescaled Prediction Bias Error.\n",
    "          - pocid_rescaled (float): Rescaled Percentage of Correct Indication Direction.\n",
    "          - mase_rescaled (float): Rescaled Mean Absolute Scaled Error.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Generating the attribute-value table (normalized)\n",
    "    data_normalized, scaler = rolling_window(data[\"m3\"], window)\n",
    "\n",
    "    # Splitting the data into train/test considering a prediction horizon of 12 months\n",
    "    X_train, X_test, y_train, y_test = train_test_split_window(data_normalized, horizon)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42, shuffle=False)\n",
    "    \n",
    "    # Define Early Stopping\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='root_mean_squared_error', patience=10, mode='min', verbose= 1)\n",
    "    \n",
    "    tuner = BayesianOptimization(\n",
    "        hypermodel=ModelBuilder(),\n",
    "        objective=Objective('root_mean_squared_error', direction='min'),\n",
    "        num_initial_points= 3,\n",
    "        alpha=0.0001,\n",
    "        beta=2.6,\n",
    "        seed=42,\n",
    "        max_retries_per_trial= 0,\n",
    "        max_consecutive_failed_trials= 3,\n",
    "        directory='tuner2',\n",
    "        project_name=f'lstm_{state}_{product}'\n",
    "    )\n",
    "    \n",
    "    tuner.search(X_train, y_train, epochs=epochs, \n",
    "                        validation_data=(X_val, y_val), \n",
    "                        batch_size= 32,\n",
    "                        verbose=verbose, callbacks=[early_stopping])\n",
    "        \n",
    "    # Get the best model\n",
    "    best_model = tuner.get_best_models()[0]\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters()[0].values\n",
    "\n",
    "    gc.collect() \n",
    "    K.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    del tuner\n",
    "    \n",
    "    # Predicting\n",
    "    predictions = recursive_multistep_forecasting(X_test, best_model, horizon)    \n",
    "\n",
    "    # Calculating evaluation metrics\n",
    "    rmse_result = rmse(y_test.values, predictions)\n",
    "    mape_result = mape(y_test.values, predictions)\n",
    "    pbe_result = pbe(y_test.values, predictions)\n",
    "    pocid_result = pocid(y_test.values, predictions)\n",
    "    \n",
    "    if show_plot:\n",
    "\n",
    "        # Plotting normalized predictions\n",
    "        plt.figure(figsize=(8, 2))\n",
    "        plt.title('Normalized Predictions')\n",
    "        plt.plot(y_test.values, label='Actual')\n",
    "        plt.plot(predictions, linewidth=5, alpha=0.4, label='Predicted')\n",
    "        plt.scatter(range(len(y_test)), y_test.values, color='blue')\n",
    "        plt.scatter(range(len(predictions)), predictions, color='red')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(3,3))\n",
    "        plt.scatter(y_test.values, predictions, alpha=0.4)\n",
    "        plt.axline((0, 0), slope=1, linestyle='dotted', color='gray')\n",
    "        plt.xlabel('Actual values')\n",
    "        plt.ylabel('Predicted values')\n",
    "        plt.xlim([-2, 2])\n",
    "        plt.ylim([-2, 2])\n",
    "    \n",
    "    if rescaling:\n",
    "        if return_model:\n",
    "            rmse_result_rescaled, mape_result_rescaled, pbe_result_rescaled, pocid_result_rescaled, mase_result_rescaled, mae_result_rescaled = rescaled_predicted_values(horizon= horizon, data= data, predictions= predictions, scaler= scaler, show_plot=show_plot)\n",
    "            return best_model, rmse_result, mape_result, pbe_result, pocid_result, best_hyperparameters, rmse_result_rescaled, mape_result_rescaled, pbe_result_rescaled, pocid_result_rescaled, mase_result_rescaled\n",
    "        else:\n",
    "            rmse_result_rescaled, mape_result_rescaled, pbe_result_rescaled, pocid_result_rescaled, mase_result_rescaled, mae_result_rescaled = rescaled_predicted_values(horizon= horizon, data= data, predictions= predictions, scaler= scaler, show_plot=show_plot)\n",
    "        return rmse_result, mape_result, pbe_result, pocid_result, best_hyperparameters, rmse_result_rescaled, mape_result_rescaled, pbe_result_rescaled, pocid_result_rescaled, mase_result_rescaled\n",
    "    else:\n",
    "        if return_model:\n",
    "            return best_model, rmse_result, mape_result, pbe_result, pocid_result, best_hyperparameters\n",
    "        else:\n",
    "            return rmse_result, mape_result, pbe_result, pocid_result, best_hyperparameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thread_simple_train():    \n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    os.environ['PYTHONHASHSEED'] = str(42)\n",
    "    tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    print(physical_devices)\n",
    "    if physical_devices:\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting memory growth: {e}\")\n",
    "    import time\n",
    "    time.sleep(2)\n",
    "    print(\"Finished create_thread_simple_train\")\n",
    "    \n",
    "    # load database test\n",
    "    data_filtered_test = pd.read_csv(\"../database/venda_process/mensal/uf/glp/mensal_pr_glp.csv\", sep=\";\",  parse_dates=['timestamp'], date_parser=convert_date)\n",
    "\n",
    "    print(\" ========== Starting univariate test for the state of ParanÃ¡ - GLP ==========\")\n",
    "\n",
    "    start_timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"\\nExecution started at: {start_timestamp}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Running the LSTM model\n",
    "    rmse_result, mape_result, pbe_result, pocid_result, best_param, rmse_result_rescaled, mape_result_rescaled, pbe_result_rescaled, pocid_result_rescaled, mase_result_rescaled = \\\n",
    "    run_lstm_model(horizon=12, window=12, data=data_filtered_test, epochs=200, state=\"pr\", product=\"glp\", rescaling=True, show_plot=True, verbose=1)\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(f\"Function execution time: {execution_time:.2f} seconds\")\n",
    "    print(f\"Execution ended at: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    # Results without scaling\n",
    "    print(\"\\nResults without scaling:\")\n",
    "    print(f'RMSE: {rmse_result}')\n",
    "    print(f'MAPE: {mape_result}')\n",
    "    print(f'PBE: {pbe_result}')\n",
    "    print(f'POCID: {pocid_result}')\n",
    "\n",
    "    # Rescaled results\n",
    "    print(\"\\nRescaled results:\")\n",
    "    print(f'Rescaled RMSE: {rmse_result_rescaled}')\n",
    "    print(f'Rescaled MAPE: {mape_result_rescaled}')\n",
    "    print(f'Rescaled PBE: {pbe_result_rescaled}')\n",
    "    print(f'Rescaled POCID: {pocid_result_rescaled}')\n",
    "    print(f'Rescaled MASE: {mase_result_rescaled}')\n",
    "\n",
    "    # Display the results\n",
    "    print(\"\\nBest parameters found: \", best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping through all states and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lstm_in_thread(state, product, horizon, window, data_filtered, epochs, verbose, save_model, bool_save, lock):\n",
    "    try:\n",
    "        # Rodar o modelo LSTM\n",
    "        model, rmse_result, mape_result, pbe_result, pocid_result, best_hyperparameters, rmse_result_rescaled, mape_result_rescaled, pbe_result_rescaled, pocid_result_rescaled, mase_result_rescaled = \\\n",
    "        run_lstm_model(horizon=horizon, window=window, data=data_filtered, epochs=epochs, state=state, product=product, rescaling=True, show_plot=False, verbose=verbose, return_model=True)\n",
    "\n",
    "        # Salvar modelo\n",
    "        if save_model and model is not None:\n",
    "            directory = \"saved_models2\"\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "\n",
    "            state_directory = os.path.join(directory, state)\n",
    "            if not os.path.exists(state_directory):\n",
    "                os.makedirs(state_directory)\n",
    "\n",
    "            model_name = f\"lstm_{state}_{product}\"\n",
    "            model_path = os.path.join(state_directory, f\"{model_name}.pkl\")\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "\n",
    "        with lock:\n",
    "            results_df = pd.DataFrame([{'HORIZON': horizon,\n",
    "                                        'WINDOW': window,\n",
    "                                        'EPOCHS': epochs,\n",
    "                                        'BEST_PARAM': str(best_hyperparameters),\n",
    "                                        'VAL_DROPOUT': best_hyperparameters['val_dropout'],\n",
    "                                        'NUM1_LSTM': best_hyperparameters['num1_lstm'],\n",
    "                                        'NUM2_LSTM': best_hyperparameters['num2_lstm'],\n",
    "                                        'OPTIMIZER': best_hyperparameters['optimizer'],\n",
    "                                        'ACTIVATION': best_hyperparameters['activation'],\n",
    "                                        \"ACTIVATION_DENSE\": best_hyperparameters['activation_dense'],\n",
    "                                        'STATE': state,\n",
    "                                        'PRODUCT': product,\n",
    "                                        'RMSE': rmse_result,\n",
    "                                        'MAPE': mape_result,\n",
    "                                        'PBE': pbe_result,\n",
    "                                        'POCID': pocid_result,\n",
    "                                        'RMSE_RESCALED': rmse_result_rescaled,\n",
    "                                        'MAPE_RESCALED': mape_result_rescaled,\n",
    "                                        'PBE_RESCALED': pbe_result_rescaled,\n",
    "                                        'POCID_RESCALED': pocid_result_rescaled,\n",
    "                                        'MASE_RESCALED': mase_result_rescaled,\n",
    "                                        'ERROR': np.nan}])\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for product '{product}' in state '{state}': {e}\")\n",
    "        with lock:\n",
    "            results_df = pd.DataFrame([{'HORIZON': np.nan,\n",
    "                                        'WINDOW': np.nan,\n",
    "                                        'EPOCHS': np.nan,\n",
    "                                        'BEST_PARAM': np.nan,\n",
    "                                        'VAL_DROPOUT': np.nan,\n",
    "                                        'NUM1_LSTM': np.nan,\n",
    "                                        'NUM2_LSTM': np.nan,\n",
    "                                        'OPTIMIZER': np.nan,\n",
    "                                        'ACTIVATION': np.nan,\n",
    "                                        \"ACTIVATION_DENSE\": np.nan,\n",
    "                                        'STATE': state,\n",
    "                                        'PRODUCT': product,\n",
    "                                        'RMSE': np.nan,\n",
    "                                        'MAPE': np.nan,\n",
    "                                        'PBE': np.nan,\n",
    "                                        'POCID': np.nan,\n",
    "                                        'RMSE_RESCALED': np.nan,\n",
    "                                        'MAPE_RESCALED': np.nan,\n",
    "                                        'PBE_RESCALED': np.nan,\n",
    "                                        'POCID_RESCALED': np.nan,\n",
    "                                        'MASE_RESCALED': np.nan,\n",
    "                                        'ERROR': f\"An error occurred for product '{product}' in state '{state}': {e}\"}])\n",
    "            \n",
    "    if bool_save:\n",
    "        directory = 'result'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        file_path = os.path.join(directory, 'lstm_results2.xlsx')\n",
    "        if os.path.exists(file_path):\n",
    "            existing_df = pd.read_excel(file_path)\n",
    "        else:\n",
    "            existing_df = pd.DataFrame()\n",
    "\n",
    "        combined_df = pd.concat([existing_df, results_df], ignore_index=True)\n",
    "        combined_df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_lstm(horizon, window, epochs, verbose, bool_save, save_model=None):\n",
    "    \"\"\"\n",
    "    Loop through LSTM model with different configurations.\n",
    "\n",
    "    Parameters:\n",
    "        - horizon: int, prediction horizon.\n",
    "        - window: int, length of the window for attribute-value table generation.\n",
    "        - epochs: int, number of epochs for training the LSTM model.\n",
    "        - verbose: int, controls the verbosity of the training process. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "        - bool_save: bool, flag indicating whether to save the trained models.\n",
    "        - save_model: bool, save models.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    semaphore = threading.Semaphore(1)\n",
    "\n",
    "    all_data = pd.read_csv(\"../database/combined_data.csv\", sep=\";\")\n",
    "\n",
    "    # Initialize the dictionary\n",
    "    state_product_dict = {}\n",
    "\n",
    "    # Iterate over unique states\n",
    "    for state in all_data['state'].unique():\n",
    "        # Filter products corresponding to this state\n",
    "        products = all_data[all_data['state'] == state]['product'].unique()\n",
    "        # Add to the dictionary\n",
    "        state_product_dict[state] = list(products)\n",
    "\n",
    "    for state, products in state_product_dict.items():\n",
    "        for product in products:\n",
    "            print(f\"========== State: {state}, product: {product} ==========\")\n",
    "\n",
    "            start_timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"\\nExecution started at: {start_timestamp}\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            random.seed(42)\n",
    "            np.random.seed(42)\n",
    "            tf.random.set_seed(42)\n",
    "            os.environ['PYTHONHASHSEED'] = str(42)\n",
    "            keras.utils.set_random_seed(42)\n",
    "\n",
    "            # Filtrar os dados\n",
    "            data_filtered = all_data[(all_data['state'] == state) & (all_data['product'] == product)]\n",
    "\n",
    "            thread = multiprocessing.Process(target=run_lstm_in_thread, args=(state, product, horizon, window, data_filtered, epochs, verbose, save_model, bool_save, semaphore))\n",
    "            thread.start()\n",
    "            thread.join()\n",
    "    \n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            print(f\"Function execution time: {execution_time:.2f} seconds\")\n",
    "            print(f\"Execution ended at: {time.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
